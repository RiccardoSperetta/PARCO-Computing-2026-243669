#!/bin/bash
# Job name
#PBS -N hybridBFS
# Output files
#PBS -o ./hybrid.o
#PBS -e ./hybrid.e
# Queue name
#PBS -q shortCPUQ
# Set the maximum wall time
#PBS -l walltime=0:45:00
# Number of nodes, cpus, mpi processors and amount of memory
#PBS -l select=4:ncpus=32:mpiprocs=32:mem=32gb
# In order to maximize the inter-node distribution
#PBS -l place=scatter

# Modules for python and MPI
module load GCC/11.2.0
module load OpenMPI/4.1.1-GCC-11.2.0

gcc --version
mpicc --version

# Get the list of unique nodes assigned to the job
NODES=$(sort -u $PBS_NODEFILE)
echo The running nodes are $NODES

# Loop through each node and get architecture information
for NODE in $NODES; do
    echo "Node: $NODE"
    ssh $NODE "lscpu"
done

export OMP_NUM_THREADS=8
export OMP_PROC_BIND=close
export OMP_PLACES=cores


# Select the working directory 
cd $PBS_O_WORKDIR

echo "============================================"
echo "Job started at: $(date '+%Y-%m-%d %H:%M:%S')"

make

# STRONG SCALING
# for each graph (in CSR format)
for graph in data/csr/*.bin; do
    # ignore R-MAT for now
    if [[ "${graph}" == data/csr/kronecker* ]]; then
        continue
    fi

    # Determine the results directory name based on the graph name
    dir="results/$(basename "${graph}" .bin)"

    # going from 1 to 128 MPI processes
    echo "[ BENCHMARKING ${graph} with hybrid BFS ]"
    for np in 8 16 32 64 128; do
        # since we're using 8 cores per MPI process:
        adjusted=$((np/8))

        echo "Running with $adjusted processes - with a total of $np cores"
        
        # if the results file already exists: skip
        if [[ -f "${dir}/hybrid${np}.txt" ]]; then
            echo "already done, skip"
            continue
        fi

        # for 64 different (randomized) search keys (repetitions inside the program)
        mpirun -np $adjusted --hostfile $PBS_NODEFILE \
            --map-by node:PE=8 --bind-to core \
            --report-bindings \
            ./BFS_hybrid.out ${graph} hybrid${np}
        echo "======== $np run is OVER ========"
        echo "======== $np run is OVER ========" >> hybrid.e
        echo ""
    done
    echo "[ DONE ${graph} ]"
done

# WEAK SCALING
for graph in data/csr/kronecker*.bin; do
    echo "[ BENCHMARKING Kronecker generated graph for ${number} cores (with ${number} cores) ]"

    # Extract the number in the filename
    number=$(basename "${graph}" | sed -E 's/kronecker([0-9]+)\.bin/\1/')
    # since we're using 8 cores per MPI process:
    adjusted=$((number/8))
    if [[ -f "results/weak_scaling/hybrid${np}.txt" ]]; then
        echo "already done, skip"
        continue
    fi

    mpirun -np $adjusted --hostfile $PBS_NODEFILE \
            --map-by node:PE=8 --bind-to core \
            --report-bindings \
            ./BFS_hybrid.out ${graph} hybrid${number}
    echo "[ DONE ${graph} ]"
    echo ""
done

echo "[ DONE hybrid BFS benchmark ]"
echo "============================================"
echo "Job finished  at: $(date '+%Y-%m-%d %H:%M:%S')"